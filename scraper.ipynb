{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from -r requirements.txt (line 1)) (4.12.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from -r requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: nltk in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from -r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: requests in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from -r requirements.txt (line 4)) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from beautifulsoup4->-r requirements.txt (line 1)) (2.5)\n",
      "Requirement already satisfied: click in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from nltk->-r requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from nltk->-r requirements.txt (line 3)) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from nltk->-r requirements.txt (line 3)) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from nltk->-r requirements.txt (line 3)) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages (from requests->-r requirements.txt (line 4)) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\my pc\\appdata\\roaming\\python\\python39\\site-packages (from click->nltk->-r requirements.txt (line 3)) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\miniconda3\\envs\\tf\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\My\n",
      "[nltk_data]     Pc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code:  200\n"
     ]
    }
   ],
   "source": [
    "## Getting webpage content by http request\n",
    "url = 'https://www.dice.com/jobs/q-Android+Developer-jobs'\n",
    "response = requests.get(url)\n",
    "print('Status code: ', response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Android Developer Jobs | Dice.com</title>\n"
     ]
    }
   ],
   "source": [
    "## Creating parser\n",
    "soup = BeautifulSoup(response.text,  \"html.parser\")\n",
    "\n",
    "## Check text content\n",
    "print(soup.find('title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title - Android Developer\n"
     ]
    }
   ],
   "source": [
    "## Retrieving job titles\n",
    "jobs_titles= soup.find_all(class_='hidden jcl-accessibility-text sc-dhi-job-search-job-card-layout-full')\n",
    "\n",
    "print(jobs_titles[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: Android Developer Location: Santa Cruz, CA (outer Silicon Valley) – position is hybrid (2 days per week onsite).   Exp: 10-12+yrs    Interview: 2 video conferences, then hiring decision. Our Client is seeking an Android Developer for an extendable 6-month contract position. This is a hybrid position – minimum of 2 days per week onsite in Santa Cruz, CA. Responsibilities: Professionalize, optimize, and document code which is \"hacked together\" that it is robust, scalable, and documented;\n"
     ]
    }
   ],
   "source": [
    "## Retrieving job descriptions\n",
    "jobs_descriptions = soup.find_all(class_='job-summary-full p-reg-100 sc-dhi-job-search-job-card-layout-full')\n",
    "\n",
    "print(jobs_descriptions[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing website traversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code:  200\n"
     ]
    }
   ],
   "source": [
    "## Getting webpage content by http request\n",
    "url = 'https://www.dice.com/jobs/browsejobs/q-title-djt-A-jobs'\n",
    "response = requests.get(url)\n",
    "print('Status code: ', response.status_code)\n",
    "\n",
    "## Creating parser\n",
    "main_soup = BeautifulSoup(response.text,  \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
      "3.25\n"
     ]
    }
   ],
   "source": [
    "## Getting job categories\n",
    "categories = [category.text for category in main_soup.find_all(class_='mR5') if len(category.text) == 1]\n",
    "print(categories)\n",
    "print(len(categories)/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.dice.com/jobs/browsejobs/q-title-djt-A-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-B-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-C-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-D-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-E-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-F-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-G-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-H-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-I-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-J-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-K-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-L-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-M-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-N-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-O-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-P-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-Q-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-R-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-S-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-T-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-U-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-V-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-W-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-X-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-Y-jobs', 'https://www.dice.com/jobs/browsejobs/q-title-djt-Z-jobs']\n"
     ]
    }
   ],
   "source": [
    "## Getting job category links\n",
    "categories_links = [url.replace(url.split('-')[-2],category) for category in categories]\n",
    "\n",
    "print(categories_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code:  200\n"
     ]
    }
   ],
   "source": [
    "## Getting job titles per category link\n",
    "response = requests.get(categories_links[0])\n",
    "print('Status code: ', response.status_code)\n",
    "\n",
    "## Creating parser\n",
    "category_soup = BeautifulSoup(response.text,  \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Advisory - Identity and Access Management- Senior Consu', '/jobs/q-Advisory+%26%2345+Identity+and+Access+Management%26%2345+Senior+Consu-jobs'), ('Android Developer', '/jobs/q-Android+Developer-jobs'), ('Automation Engineer', '/jobs/q-Automation+Engineer-jobs'), ('Azure DevOps Engineer', '/jobs/q-Azure+DevOps+Engineer-jobs'), ('AEM Developer', '/jobs/q-AEM+Developer-jobs'), ('Application Developer', '/jobs/q-Application+Developer-jobs'), ('Axiom Developer', '/jobs/q-Axiom+Developer-jobs'), ('Angular Developer', '/jobs/q-Angular+Developer-jobs'), ('AWS/Azure Cloud Security Engineer (Remote - Delivery Ce', '/jobs/q-AWS%26%2347Azure+Cloud+Security+Engineer+%28Remote+%26%2345+Delivery+Ce-jobs'), ('Appian Developer', '/jobs/q-Appian+Developer-jobs'), ('Actimize Developer', '/jobs/q-Actimize+Developer-jobs'), ('AWS Data Engineer', '/jobs/q-AWS+Data+Engineer-jobs'), ('Applications Architect', '/jobs/q-Applications+Architect-jobs'), ('Azure Cloud Engineer', '/jobs/q-Azure+Cloud+Engineer-jobs'), ('AWS Cloud Architect', '/jobs/q-AWS+Cloud+Architect-jobs'), ('Azure Data Engineer', '/jobs/q-Azure+Data+Engineer-jobs'), ('AWS DevOps Engineer', '/jobs/q-AWS+DevOps+Engineer-jobs'), ('AWS Cloud Engineer', '/jobs/q-AWS+Cloud+Engineer-jobs'), ('Android Engineer', '/jobs/q-Android+Engineer-jobs'), ('Azure Data Architect', '/jobs/q-Azure+Data+Architect-jobs'), ('Automation Tester', '/jobs/q-Automation+Tester-jobs'), ('Azure Architect', '/jobs/q-Azure+Architect-jobs'), ('Azure Cloud Architect', '/jobs/q-Azure+Cloud+Architect-jobs'), ('Application Engineer', '/jobs/q-Application+Engineer-jobs'), ('Application Security Engineer', '/jobs/q-Application+Security+Engineer-jobs'), ('Abinitio Developer', '/jobs/q-Abinitio+Developer-jobs'), ('Accountant', '/jobs/q-Accountant-jobs'), ('Audio Visual Technician', '/jobs/q-Audio+Visual+Technician-jobs'), ('API Developer', '/jobs/q-API+Developer-jobs'), ('Applications Developer', '/jobs/q-Applications+Developer-jobs'), ('Azure Engineer', '/jobs/q-Azure+Engineer-jobs'), ('AV Technician', '/jobs/q-AV+Technician-jobs'), ('Active Directory Engineer', '/jobs/q-Active+Directory+Engineer-jobs'), ('Application Support Analyst', '/jobs/q-Application+Support+Analyst-jobs'), ('Applications Engineer', '/jobs/q-Applications+Engineer-jobs'), ('Account Executive', '/jobs/q-Account+Executive-jobs'), ('Agile Project Manager', '/jobs/q-Agile+Project+Manager-jobs'), ('Azure Devops Engineer', '/jobs/q-Azure+Devops+Engineer-jobs'), ('AI Architect', '/jobs/q-AI+Architect-jobs'), ('Analyst II, Systems Engineering', '/jobs/q-Analyst+II%2C+Systems+Engineering-jobs'), ('Application Architect', '/jobs/q-Application+Architect-jobs'), ('Application Support Engineer', '/jobs/q-Application+Support+Engineer-jobs'), ('Automation Architect', '/jobs/q-Automation+Architect-jobs'), ('AEM Architect', '/jobs/q-AEM+Architect-jobs'), ('ASP.NET Developer', '/jobs/q-ASP.NET+Developer-jobs'), ('AWS Data Architect', '/jobs/q-AWS+Data+Architect-jobs'), ('Accounting/Finance - Accountant 3--Irving, TX-- Remote position--11966-1', '/jobs/q-Accounting%26%2347Finance+%26%2345+Accountant+3%26%2345%26%2345Irving%2C+TX%26%2345%26%2345+Remote+position%26%2345%26%234511966%26%23451-jobs'), ('Alarm Technician', '/jobs/q-Alarm+Technician-jobs'), ('Application Programmer', '/jobs/q-Application+Programmer-jobs'), ('Athletic Trainer', '/jobs/q-Athletic+Trainer-jobs'), ('AWS Cloud Administrator', '/jobs/q-AWS+Cloud+Administrator-jobs'), ('AWS Engineer', '/jobs/q-AWS+Engineer-jobs'), ('AWS Solution Architect', '/jobs/q-AWS+Solution+Architect-jobs'), ('AWS/Azure Architect Senior Consultant (Delivery Center/', '/jobs/q-AWS%26%2347Azure+Architect+Senior+Consultant+%28Delivery+Center%26%2347-jobs'), ('Account Manager', '/jobs/q-Account+Manager-jobs'), ('Accounts Payable Analyst', '/jobs/q-Accounts+Payable+Analyst-jobs'), ('Agile Coach', '/jobs/q-Agile+Coach-jobs'), ('Angular UI Developer', '/jobs/q-Angular+UI+Developer-jobs'), ('Ansible Automation Engineer', '/jobs/q-Ansible+Automation+Engineer-jobs'), ('Application Support Specialist', '/jobs/q-Application+Support+Specialist-jobs'), ('Asset Manager', '/jobs/q-Asset+Manager-jobs'), ('Associate Software Support Specialist', '/jobs/q-Associate+Software+Support+Specialist-jobs'), ('Audit Manager', '/jobs/q-Audit+Manager-jobs'), ('Azure .NET Developer', '/jobs/q-Azure+.NET+Developer-jobs'), ('AEM QC Analyst', '/jobs/q-AEM+QC+Analyst-jobs'), ('AI/ML Engineer', '/jobs/q-AI%26%2347ML+Engineer-jobs'), ('AWS Architect', '/jobs/q-AWS+Architect-jobs'), ('AWS Developer', '/jobs/q-AWS+Developer-jobs'), ('AWS Infrastructure Architect', '/jobs/q-AWS+Infrastructure+Architect-jobs'), ('AWS Solutions Architect', '/jobs/q-AWS+Solutions+Architect-jobs'), ('Ab Initio Developer', '/jobs/q-Ab+Initio+Developer-jobs'), ('Accounting Analyst', '/jobs/q-Accounting+Analyst-jobs'), ('Agile Project Manager - New York', '/jobs/q-Agile+Project+Manager+%26%2345+New+York-jobs'), ('Airframe Design Engineer', '/jobs/q-Airframe+Design+Engineer-jobs'), ('Anaconda Administrator', '/jobs/q-Anaconda+Administrator-jobs'), ('Android Reverse Engineer', '/jobs/q-Android+Reverse+Engineer-jobs'), ('Application Development Manager', '/jobs/q-Application+Development+Manager-jobs'), ('Application Engineering Lead', '/jobs/q-Application+Engineering+Lead-jobs'), ('Application Support', '/jobs/q-Application+Support-jobs'), ('Art Director', '/jobs/q-Art+Director-jobs'), ('Asset Management Technician', '/jobs/q-Asset+Management+Technician-jobs'), ('Asset Shipping Specialist', '/jobs/q-Asset+Shipping+Specialist-jobs'), ('Associate, Technology Service Desk/On-Site Support Analyst II', '/jobs/q-Associate%2C+Technology+Service+Desk%26%2347On%26%2345Site+Support+Analyst+II-jobs'), ('Axway Developer', '/jobs/q-Axway+Developer-jobs'), ('Azure Solutions Architect', '/jobs/q-Azure+Solutions+Architect-jobs'), ('AEM Solutions Developer', '/jobs/q-AEM+Solutions+Developer-jobs'), ('AEP Developer', '/jobs/q-AEP+Developer-jobs'), ('AI Developer', '/jobs/q-AI+Developer-jobs'), ('AI Strategist', '/jobs/q-AI+Strategist-jobs'), ('AI/ML Engineer, Therapeutic Protein Design', '/jobs/q-AI%26%2347ML+Engineer%2C+Therapeutic+Protein+Design-jobs'), ('AI/ML Sales Representative', '/jobs/q-AI%26%2347ML+Sales+Representative-jobs'), ('AML/BSA Specialist', '/jobs/q-AML%26%2347BSA+Specialist-jobs'), ('AWS Cloud Infrastructure Engineer', '/jobs/q-AWS+Cloud+Infrastructure+Engineer-jobs'), ('Access Control And CCTV Security Technician - Pavion', '/jobs/q-Access+Control+And+CCTV+Security+Technician+%26%2345+Pavion-jobs'), ('Account Executive II', '/jobs/q-Account+Executive+II-jobs'), ('Accounting Manager', '/jobs/q-Accounting+Manager-jobs'), ('Accounting Manager - New York, NY', '/jobs/q-Accounting+Manager+%26%2345+New+York%2C+NY-jobs'), ('Accounting/Finance - Financial Analyst 3', '/jobs/q-Accounting%26%2347Finance+%26%2345+Financial+Analyst+3-jobs'), ('Acquisition Program Analyst, Sr', '/jobs/q-Acquisition+Program+Analyst%2C+Sr-jobs'), ('Acquisition Systems Engineer', '/jobs/q-Acquisition+Systems+Engineer-jobs')]\n"
     ]
    }
   ],
   "source": [
    "## Getting job titles and job links\n",
    "## Output is a list with array of each element (job_title,job_title_link)\n",
    "job_titles_in_category = [(job_title.text,job_title['href']) for job_title in category_soup.find_all(class_='mR5 browse-job-detail')]\n",
    "\n",
    "print(job_titles_in_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.dice.com/jobs/q-Advisory+%26%2345+Identity+and+Access+Management%26%2345+Senior+Consu-jobs', 'https://www.dice.com/jobs/q-Android+Developer-jobs', 'https://www.dice.com/jobs/q-Automation+Engineer-jobs', 'https://www.dice.com/jobs/q-Azure+DevOps+Engineer-jobs', 'https://www.dice.com/jobs/q-AEM+Developer-jobs', 'https://www.dice.com/jobs/q-Application+Developer-jobs', 'https://www.dice.com/jobs/q-Axiom+Developer-jobs', 'https://www.dice.com/jobs/q-Angular+Developer-jobs', 'https://www.dice.com/jobs/q-AWS%26%2347Azure+Cloud+Security+Engineer+%28Remote+%26%2345+Delivery+Ce-jobs', 'https://www.dice.com/jobs/q-Appian+Developer-jobs', 'https://www.dice.com/jobs/q-Actimize+Developer-jobs', 'https://www.dice.com/jobs/q-AWS+Data+Engineer-jobs', 'https://www.dice.com/jobs/q-Applications+Architect-jobs', 'https://www.dice.com/jobs/q-Azure+Cloud+Engineer-jobs', 'https://www.dice.com/jobs/q-AWS+Cloud+Architect-jobs', 'https://www.dice.com/jobs/q-Azure+Data+Engineer-jobs', 'https://www.dice.com/jobs/q-AWS+DevOps+Engineer-jobs', 'https://www.dice.com/jobs/q-AWS+Cloud+Engineer-jobs', 'https://www.dice.com/jobs/q-Android+Engineer-jobs', 'https://www.dice.com/jobs/q-Azure+Data+Architect-jobs', 'https://www.dice.com/jobs/q-Automation+Tester-jobs', 'https://www.dice.com/jobs/q-Azure+Architect-jobs', 'https://www.dice.com/jobs/q-Azure+Cloud+Architect-jobs', 'https://www.dice.com/jobs/q-Application+Engineer-jobs', 'https://www.dice.com/jobs/q-Application+Security+Engineer-jobs', 'https://www.dice.com/jobs/q-Abinitio+Developer-jobs', 'https://www.dice.com/jobs/q-Accountant-jobs', 'https://www.dice.com/jobs/q-Audio+Visual+Technician-jobs', 'https://www.dice.com/jobs/q-API+Developer-jobs', 'https://www.dice.com/jobs/q-Applications+Developer-jobs', 'https://www.dice.com/jobs/q-Azure+Engineer-jobs', 'https://www.dice.com/jobs/q-AV+Technician-jobs', 'https://www.dice.com/jobs/q-Active+Directory+Engineer-jobs', 'https://www.dice.com/jobs/q-Application+Support+Analyst-jobs', 'https://www.dice.com/jobs/q-Applications+Engineer-jobs', 'https://www.dice.com/jobs/q-Account+Executive-jobs', 'https://www.dice.com/jobs/q-Agile+Project+Manager-jobs', 'https://www.dice.com/jobs/q-Azure+Devops+Engineer-jobs', 'https://www.dice.com/jobs/q-AI+Architect-jobs', 'https://www.dice.com/jobs/q-Analyst+II%2C+Systems+Engineering-jobs', 'https://www.dice.com/jobs/q-Application+Architect-jobs', 'https://www.dice.com/jobs/q-Application+Support+Engineer-jobs', 'https://www.dice.com/jobs/q-Automation+Architect-jobs', 'https://www.dice.com/jobs/q-AEM+Architect-jobs', 'https://www.dice.com/jobs/q-ASP.NET+Developer-jobs', 'https://www.dice.com/jobs/q-AWS+Data+Architect-jobs', 'https://www.dice.com/jobs/q-Accounting%26%2347Finance+%26%2345+Accountant+3%26%2345%26%2345Irving%2C+TX%26%2345%26%2345+Remote+position%26%2345%26%234511966%26%23451-jobs', 'https://www.dice.com/jobs/q-Alarm+Technician-jobs', 'https://www.dice.com/jobs/q-Application+Programmer-jobs', 'https://www.dice.com/jobs/q-Athletic+Trainer-jobs', 'https://www.dice.com/jobs/q-AWS+Cloud+Administrator-jobs', 'https://www.dice.com/jobs/q-AWS+Engineer-jobs', 'https://www.dice.com/jobs/q-AWS+Solution+Architect-jobs', 'https://www.dice.com/jobs/q-AWS%26%2347Azure+Architect+Senior+Consultant+%28Delivery+Center%26%2347-jobs', 'https://www.dice.com/jobs/q-Account+Manager-jobs', 'https://www.dice.com/jobs/q-Accounts+Payable+Analyst-jobs', 'https://www.dice.com/jobs/q-Agile+Coach-jobs', 'https://www.dice.com/jobs/q-Angular+UI+Developer-jobs', 'https://www.dice.com/jobs/q-Ansible+Automation+Engineer-jobs', 'https://www.dice.com/jobs/q-Application+Support+Specialist-jobs', 'https://www.dice.com/jobs/q-Asset+Manager-jobs', 'https://www.dice.com/jobs/q-Associate+Software+Support+Specialist-jobs', 'https://www.dice.com/jobs/q-Audit+Manager-jobs', 'https://www.dice.com/jobs/q-Azure+.NET+Developer-jobs', 'https://www.dice.com/jobs/q-AEM+QC+Analyst-jobs', 'https://www.dice.com/jobs/q-AI%26%2347ML+Engineer-jobs', 'https://www.dice.com/jobs/q-AWS+Architect-jobs', 'https://www.dice.com/jobs/q-AWS+Developer-jobs', 'https://www.dice.com/jobs/q-AWS+Infrastructure+Architect-jobs', 'https://www.dice.com/jobs/q-AWS+Solutions+Architect-jobs', 'https://www.dice.com/jobs/q-Ab+Initio+Developer-jobs', 'https://www.dice.com/jobs/q-Accounting+Analyst-jobs', 'https://www.dice.com/jobs/q-Agile+Project+Manager+%26%2345+New+York-jobs', 'https://www.dice.com/jobs/q-Airframe+Design+Engineer-jobs', 'https://www.dice.com/jobs/q-Anaconda+Administrator-jobs', 'https://www.dice.com/jobs/q-Android+Reverse+Engineer-jobs', 'https://www.dice.com/jobs/q-Application+Development+Manager-jobs', 'https://www.dice.com/jobs/q-Application+Engineering+Lead-jobs', 'https://www.dice.com/jobs/q-Application+Support-jobs', 'https://www.dice.com/jobs/q-Art+Director-jobs', 'https://www.dice.com/jobs/q-Asset+Management+Technician-jobs', 'https://www.dice.com/jobs/q-Asset+Shipping+Specialist-jobs', 'https://www.dice.com/jobs/q-Associate%2C+Technology+Service+Desk%26%2347On%26%2345Site+Support+Analyst+II-jobs', 'https://www.dice.com/jobs/q-Axway+Developer-jobs', 'https://www.dice.com/jobs/q-Azure+Solutions+Architect-jobs', 'https://www.dice.com/jobs/q-AEM+Solutions+Developer-jobs', 'https://www.dice.com/jobs/q-AEP+Developer-jobs', 'https://www.dice.com/jobs/q-AI+Developer-jobs', 'https://www.dice.com/jobs/q-AI+Strategist-jobs', 'https://www.dice.com/jobs/q-AI%26%2347ML+Engineer%2C+Therapeutic+Protein+Design-jobs', 'https://www.dice.com/jobs/q-AI%26%2347ML+Sales+Representative-jobs', 'https://www.dice.com/jobs/q-AML%26%2347BSA+Specialist-jobs', 'https://www.dice.com/jobs/q-AWS+Cloud+Infrastructure+Engineer-jobs', 'https://www.dice.com/jobs/q-Access+Control+And+CCTV+Security+Technician+%26%2345+Pavion-jobs', 'https://www.dice.com/jobs/q-Account+Executive+II-jobs', 'https://www.dice.com/jobs/q-Accounting+Manager-jobs', 'https://www.dice.com/jobs/q-Accounting+Manager+%26%2345+New+York%2C+NY-jobs', 'https://www.dice.com/jobs/q-Accounting%26%2347Finance+%26%2345+Financial+Analyst+3-jobs', 'https://www.dice.com/jobs/q-Acquisition+Program+Analyst%2C+Sr-jobs', 'https://www.dice.com/jobs/q-Acquisition+Systems+Engineer-jobs']\n"
     ]
    }
   ],
   "source": [
    "## Generating job links\n",
    "root_url = 'https://www.dice.com'\n",
    "job_titles_links = [root_url+job_title[1] for job_title in job_titles_in_category]\n",
    "\n",
    "print(job_titles_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code:  200\n"
     ]
    }
   ],
   "source": [
    "## Loading content of job title link\n",
    "job_title_url = job_titles_links[1]\n",
    "job_title_response = requests.get(job_title_url)\n",
    "print('Status code: ', response.status_code)\n",
    "\n",
    "## Creating parser\n",
    "job_title_soup = BeautifulSoup(job_title_response.text,  \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Position: Android Developer Location: Santa Cruz, CA (outer Silicon Valley) – position is hybrid (2 days per week onsite).   Exp: 10-12+yrs    Interview: 2 video conferences, then hiring decision. Our Client is seeking an Android Developer for an extendable 6-month contract position. This is a hybrid position – minimum of 2 days per week onsite in Santa Cruz, CA. Responsibilities: Professionalize, optimize, and document code which is \"hacked together\" that it is robust, scalable, and documented;\n"
     ]
    }
   ],
   "source": [
    "## Retrieving job descriptions\n",
    "jobs_descriptions = [description.text for description in job_title_soup.find_all(class_='job-summary-full p-reg-100 sc-dhi-job-search-job-card-layout-full')]\n",
    "\n",
    "print(jobs_descriptions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.dice.com/jobs/q-Android+Developer-jobs?page=2', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=3', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=4', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=5', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=6', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=7', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=8', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=9', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=10', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=11', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=12', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=13', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=14', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=15', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=16', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=17', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=18', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=19', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=20', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=21', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=22', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=23', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=24', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=25', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=26', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=27', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=28', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=29', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=30', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=31', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=32', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=33', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=34', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=35', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=36', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=37', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=38', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=39', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=40', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=41', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=42', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=43', 'https://www.dice.com/jobs/q-Android+Developer-jobs?page=44']\n"
     ]
    }
   ],
   "source": [
    "## Getting number of pages\n",
    "num_pages = int(soup.find(class_='sc-dhi-seds-pagination').text.split(' ')[-1])\n",
    "\n",
    "## Generating pagination links\n",
    "base_page_link = '?page='\n",
    "page_links = [job_title_url+base_page_link+str(page) for page in range(2,num_pages+1)]\n",
    "\n",
    "print(page_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n",
      "Status code:  200\n"
     ]
    }
   ],
   "source": [
    "## Getting job descriptions for every page in job title listing\n",
    "for n,page_link in enumerate(page_links):\n",
    "    ## Loading content of job title link\n",
    "    job_title_url = page_link\n",
    "    job_title_response = requests.get(job_title_url)\n",
    "    print('Status code: ', response.status_code)\n",
    "\n",
    "    ## Creating parser\n",
    "    job_title_soup = BeautifulSoup(job_title_response.text,  \"html.parser\")\n",
    "\n",
    "    ## Retrieving job descriptions\n",
    "    temp = [description.text for description in job_title_soup.find_all(class_='job-summary-full p-reg-100 sc-dhi-job-search-job-card-layout-full')]\n",
    "    jobs_descriptions = jobs_descriptions + temp\n",
    "    \n",
    "    if n > 9: break ## Testing code for pages 2-12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of job descriptions for first 12 pages: 240\n"
     ]
    }
   ],
   "source": [
    "print('Number of job descriptions for first 12 pages:',len(jobs_descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice.com scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_loader(url):\n",
    "    ## Getting webpage content by http request\n",
    "    ## Creating parser\n",
    "    headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.111 Safari/537.36'\n",
    "        }\n",
    "    response = requests.get(url, \n",
    "                            timeout=180, \n",
    "                            headers=headers, \n",
    "                            )\n",
    "    soup = BeautifulSoup(response.text,  \"html.parser\")\n",
    "    response.close()\n",
    "    return soup, response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories(soup):\n",
    "    ## Getting job categories\n",
    "    return [category.text for category in soup.find_all(class_='mR5') if len(category.text) == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_links(categories_list, url):\n",
    "    ## Gets links for indentified categories\n",
    "    return [url.replace(url.split('-')[-2],category) for category in categories_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_title_and_link(soup):\n",
    "    ## Getting job titles and job links\n",
    "    ## Output is a list with array of each element (job_title,job_title_link)\n",
    "    return [(job_title.text,job_title['href']) for job_title in soup.find_all(class_='mR5 browse-job-detail')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_links(list):\n",
    "    ## Generating job links\n",
    "    root_url = 'https://www.dice.com'\n",
    "    return [root_url+job_title[1] for job_title in list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_pages(soup):\n",
    "    ## Getting number of pages\n",
    "    checker = soup.find(class_='sc-dhi-seds-pagination')\n",
    "    if checker == None or checker == 1: return 1 ## Checking if no pages\n",
    "    return int(soup.find(class_='sc-dhi-seds-pagination').text.split(' ')[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_links(num_pages, job_title_url):\n",
    "    ## Generating pagination links\n",
    "    base_page_link = '?page='\n",
    "    return [job_title_url+base_page_link+str(page) for page in range(2,num_pages+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_descriptions(soup, stop_words = stopwords.words('english')):\n",
    "    ## Retrieving job descriptions\n",
    "    ## Applying NLP: lowercase, remove non-alphanum, remove stopwords\n",
    "    descriptions = [description.text for description in soup.find_all(class_='job-summary-full p-reg-100 sc-dhi-job-search-job-card-layout-full')] \n",
    "    for n,desc in enumerate(descriptions):\n",
    "        temp = re.sub(r\"[^ a-zA-Z]+\",' ', desc).lower().split(' ')\n",
    "        temp = [word for word in temp if word not in stop_words if len(word) > 1]\n",
    "        descriptions[n] = ' '.join(temp)\n",
    "    return ' '.join(descriptions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Category index to extract\n",
    "file=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "Category: https://www.dice.com/jobs/browsejobs/q-title-djt-B-jobs\n",
      " Job Link: https://www.dice.com/jobs/q-Business+Analyst-jobs\n",
      "       1 out of 137 pages processed\n",
      "       2 out of 137 pages processed\n",
      " Job Link: https://www.dice.com/jobs/q-Business+Systems+Analyst-jobs\n",
      "       1 out of 139 pages processed\n",
      "       2 out of 139 pages processed\n",
      " Job Link: https://www.dice.com/jobs/q-Biometrics+Senior+Consultant%26%2345+Remote%26%2347Delivery+Center+Ro-jobs\n",
      "       1 out of 15 pages processed\n",
      "       2 out of 15 pages processed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Creating main soup\n",
    "url = 'https://www.dice.com/jobs/browsejobs/q-title-djt-A-jobs' ## Starting point\n",
    "main_soup,status = soup_loader(url)\n",
    "\n",
    "## Getting job categories\n",
    "categories = get_categories(main_soup)[file]\n",
    "print(categories)\n",
    "\n",
    "## Getting job category links\n",
    "categories_links = get_category_links(categories, url)\n",
    "\n",
    "## Initializing contiainers\n",
    "jobs_descriptions=[]\n",
    "job_titles=[]\n",
    "base=100000\n",
    "key=1\n",
    "for category in categories_links:\n",
    "    try:\n",
    "        print('Category:', category)\n",
    "            \n",
    "        ## Getting job titles per category link\n",
    "        category_soup,status = soup_loader(category)\n",
    "\n",
    "        ## Getting job titles and job links\n",
    "        ## Output is a list with array of each element (job_title,job_title_link)\n",
    "        job_titles_in_category = get_job_title_and_link(category_soup)\n",
    "        job_titles += [job_title[0] for job_title in job_titles_in_category]\n",
    "        \n",
    "        ## Generating job links\n",
    "        job_titles_links = get_job_links(job_titles_in_category)\n",
    "        \n",
    "        for l,job_link in enumerate(job_titles_links): ## remove l after testing\n",
    "            print(' Job Link:',job_link)\n",
    "            job_link_descriptions = []\n",
    "            \n",
    "            ## Loading content of job title link\n",
    "            job_title_soup,status = soup_loader(job_link)\n",
    "\n",
    "            ## Getting number of pages\n",
    "            num_pages = get_num_pages(job_title_soup)\n",
    "            n=1; key+=1\n",
    "            print(f'       {1} out of {num_pages} pages processed')\n",
    "            if num_pages == 1: \n",
    "                jobs_descriptions.append({'job_id':file*base+key,'job_title':job_titles[l],'job_description':get_job_descriptions(job_title_soup)})\n",
    "                print('       Only 1 page'); continue ## Next job title if only one page\n",
    "            \n",
    "            job_link_descriptions+= get_job_descriptions(job_title_soup)\n",
    "            ## Generating pagination links\n",
    "            page_links = get_page_links(num_pages, job_link)\n",
    "            \n",
    "            ## Getting job descriptions for page>1 in job title listing\n",
    "            for page_link in page_links:\n",
    "\n",
    "                ## Loading content of job title link\n",
    "                job_title_soup,status = soup_loader(page_link)\n",
    "\n",
    "                ## Retrieving job descriptions\n",
    "                job_link_descriptions += get_job_descriptions(job_title_soup)\n",
    "                \n",
    "                print(f'       {n+1} out of {num_pages} pages processed')\n",
    "                ## Hard limiting number of jobs to scrape \n",
    "                n+=1\n",
    "                # break\n",
    "                if n == 2: break ## Getting a maximum (n+1)*20 number of job description per title\n",
    "            jobs_descriptions.append({'job_id':file*base+key,'job_title':job_titles[l],'job_description':get_job_descriptions(job_title_soup)})\n",
    "            if l == 2 : break ## Testing code for 10 jobs\n",
    "        # break ## Testing code\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving as CSV\n",
    "fieldnames = ['job_id','job_title','job_description']\n",
    "with open(f'datasets//dice_jobs_{str(file)}.csv', 'w') as csvfile:\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(jobs_descriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
